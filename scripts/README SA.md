# README SA

## Required data

1. original text
2. inserted text
3. Resulting text

Separated by |

### Process

### 1. Entity Recognition

#### 1.1. Generate the Excel sheet where the results are stored

[run_deberta_SA.py](. /run/run_deberta_SA.py)

[run_t5_SA.py](. /run/run_t5_SA.py)

Input: data needed, i.e. generated SA-related input files.

Output: Excel, including raw text, inserted text, sentiment labels of the resultant text, positive probability, negative probability.

Logic: Generate data after calling the model interface, then save it.

> Need to add extra last row index in the last column (I was already running through it, so I added it manually)

#### 1.2. Determining named entity bias

[SA_entity.py](. /entity/SA_entity.py)

Input: file generated by part 1.1.

Output: First use the final result to contain all the problematic results, with each line containing the text and number of each type of named entity.

Logic: If the insertion is judged as positive in the insertion phrase, and the likelihood of the result being negative rises after the insertion (more than 0.1) it is considered problematic.

### 2. Lexical understanding

#### 2.1. Excel sheet that generates results stores results

[run_deberta_SA.py](. /run/run_deberta_SA.py)

[run_t5_SA.py](. /run/run_t5_SA.py)

Input: data needed, i.e. generated SA-related input files.

Output: Excel, including raw text, inserted text, sentiment labels of the resultant text, positive probability, negative probability.

Logic: Generate data after calling the model interface, then save it.

> Need to add an extra last row index in the last column (I had already finished running at that time, so I added it manually)

#### 2.2. Judgment of lexical meaning comprehension

[SA_meaning.py](. /meaning/SA_meaning.py)

Input: 1.1. partially generated file

Output: Problems with judging lexical understanding using SA_meaning.py first.

Logic: data with the same original_text but different insertion terms are put in a set, two by two comparison is done in a set, if the difference in probability between the pair of data taken out is more than 0.1, then they are put in the result file. Or if the insertion language is positive, but the negative probability rises above 0.1 is also judged to be problematic.

> Manual sorting by index is required.

#### 2.3. Post-processing

[deal_SA_xlsx.py] (. /meaning/deal_SA_xlsx.py)

Input: files generated in section 2.2.

Output: final data, grouping using deal_SA_xlsx.py, and slicing of data.
